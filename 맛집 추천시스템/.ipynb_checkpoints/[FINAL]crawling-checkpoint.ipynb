{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73f32d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup \n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity=\"all\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "294806f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "camping_num   = []  # 캠핑장 고유넘버\n",
    "\n",
    "camping_type  = []  # 캠핑장 유형 (ex.캠핑,야영장 / 온천,스파 / 카페 등등..)\n",
    "camping_name  = []  # 캠핑장 이름\n",
    "camping_addr  = []  # 캠핑장 주소\n",
    "camping_score = []  # 캠핑장 평균별점\n",
    "camping_phone = []  # 캠핑장 전화번호\n",
    "camping_site  = []  # 캠핑장 사이트(site) \n",
    "camping_info1 = []  # 캠핑장 부가설명1\n",
    "camping_info2 = []  # 캠핑장 부가설명2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb9d945",
   "metadata": {},
   "source": [
    "## 고유넘버 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "886c0f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_crawl(keyword):\n",
    "    # 검색할 단어 입력\n",
    "#     keyword = '경기도 캠핑, 야영장'\n",
    "    url = f'https://map.naver.com/v5/search/{keyword}/place/'\n",
    "\n",
    "    driver = webdriver.Chrome('/Users/ds/chromedriver 2')\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    # iframe 변경\n",
    "    driver.switch_to.frame('searchIframe')\n",
    "\n",
    "    for num in tqdm(range(1,7)): # 반복을 5번\n",
    "        # END 키를 눌러서 페이지 제일 하단으로 이동\n",
    "        driver.find_element_by_xpath('//*[@id=\"_pcmap_list_scroll_container\"]').click()\n",
    "        if num == 1:\n",
    "            pass\n",
    "        else:\n",
    "            driver.find_element_by_xpath(f'//*[@id=\"app-root\"]/div/div[3]/div[2]/a[7]').click()\n",
    "\n",
    "        driver.find_element_by_tag_name('body').send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "        driver.find_element_by_tag_name('body').send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "        driver.find_element_by_tag_name('body').send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "        driver.find_element_by_tag_name('body').send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        time.sleep(2)\n",
    "\n",
    "        camping_list = soup.findAll('li', {'class':'_3p7dG f_JBZ'})\n",
    "\n",
    "        for i in tqdm(range(len(camping_list))):\n",
    "            driver.find_element_by_xpath(f'//*[@id=\"_pcmap_list_scroll_container\"]/ul/li[{str(i+1)}]/div[1]/a').send_keys(Keys.ENTER)\n",
    "            time.sleep(2)\n",
    "\n",
    "            current_url = driver.current_url # 검색이 성공된 플레이스에 대한 개별 페이지\n",
    "\n",
    "            unique_code = re.findall(r\"place/(\\d+)\", current_url)\n",
    "            camping_num.append(unique_code[0])\n",
    "            time.sleep(2)\n",
    "\n",
    "    driver.quit()# 검색할 단어 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96bb8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_crawl('함덕리 맛집')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fa6f0e",
   "metadata": {},
   "source": [
    "## 캠핑장정보 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67945107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_crawl():\n",
    "    driver = webdriver.Chrome('../driver/chromedriver')\n",
    "    for i in tqdm(camping_num):\n",
    "        new_url = f'https://pcmap.place.naver.com/accommodation/{i}/home?'\n",
    "        driver.get(new_url)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        time.sleep(1)\n",
    "        name = soup.find('span',{'class':'_3XamX'})\n",
    "        style = soup.find('span',{'class':'_3ocDE'})\n",
    "        addr = soup.find('span',{'class':'_2yqUQ'})\n",
    "        score = soup.find('span',{'class':'_1Y6hi _1A8_M'})\n",
    "        try :\n",
    "            camping_type.append(style.text)     ## 캠핑장 유형\n",
    "            camping_name.append(name.text)      ## 캠핑장 이름\n",
    "            camping_addr.append(addr.text)      ## 캠핑장 주소\n",
    "            camping_score.append(score.em.text) ## 캠핑장 평균별점\n",
    "        except:\n",
    "            camping_score.append('none')\n",
    "        ## 전화번호\n",
    "        try:     \n",
    "            phone_num = soup.find('span',{'class':'_3ZA0S'})\n",
    "            camping_phone.append(phone_num.text)        \n",
    "        except:\n",
    "            camping_phone.append('none')  \n",
    "        ## 캠핑장 사이트(site) \n",
    "        try:\n",
    "            site = soup.find('div',{'class':'_2SBb1'})\n",
    "            camping_site.append(site.text)        \n",
    "        except:\n",
    "            camping_site.append('none')\n",
    "        ## 부가설명\n",
    "        info = soup.findAll('li',{'class':'_1M_Iz'})\n",
    "        s = -1 # 부가설명1\n",
    "        t = -1 # 부가설명2\n",
    "        for i in info:\n",
    "            try:\n",
    "                a = i.find('span',{'class':'place_blind'}).text\n",
    "            except:\n",
    "                a = \"\"\n",
    "            print(a)\n",
    "            ## 부가설명1\n",
    "            if a == '편의':\n",
    "                s = 0\n",
    "                text1 = i.find('div',{'class':'_1h3B_'}).text\n",
    "            ## 부가설명2\n",
    "            if a == '설명':\n",
    "                t = 0\n",
    "                text2 = i.find('div',{'class':'_1h3B_'}).text\n",
    "        if s == 0:\n",
    "            camping_info1.append(text1)\n",
    "        else:\n",
    "            camping_info1.append('none')\n",
    "        if t == 0:\n",
    "            camping_info2.append(text2)\n",
    "        else:\n",
    "            camping_info2.append('none')\n",
    "    driver.quit()\n",
    "    \n",
    "    camping_dict = {'Num':camping_num, 'Type':camping_type, 'Name':camping_name, 'Address':camping_addr, 'Score':camping_score, 'Phone':camping_phone, 'URL':camping_site, 'info1':camping_info1, 'info2':camping_info2}\n",
    "    camp_info_df = pd.DataFrame(camping_dict)\n",
    "    camp_info = pd.DataFrame()\n",
    "    for i in range(len(camp_info_df)):\n",
    "        if camp_info_df['Type'][i] == '캠핑,야영장':\n",
    "            camp_info = camp_info.append(camp_info_df.loc[i])\n",
    "    camp_info = camp_info[['Num','Type', 'Name', 'Address', 'Phone', 'Score','URL','info1','info2']]\n",
    "    camp_info.index = range(0,len(camp_info))\n",
    "    camp_info['Num'] = camp_info['Num'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9003e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_crawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf5fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "camping_dict = {'Num':camping_num, 'Type':camping_type, 'Name':camping_name, 'Address':camping_addr, 'Score':camping_score, 'Phone':camping_phone, 'URL':camping_site, 'info1':camping_info1, 'info2':camping_info2}\n",
    "camp_info_df = pd.DataFrame(camping_dict)\n",
    "gyeonggi_camp_info = pd.DataFrame()\n",
    "for i in range(len(camp_info_df)):\n",
    "    if camp_info_df['Type'][i] == '캠핑,야영장':\n",
    "        gyeonggi_camp_info = gyeonggi_camp_info.append(camp_info_df.loc[i])\n",
    "gyeonggi_camp_info = gyeonggi_camp_info[['Num','Type', 'Name', 'Address', 'Phone', 'Score','URL','info1','info2']]\n",
    "gyeonggi_camp_info.index = range(0,len(gyeonggi_camp_info))\n",
    "gyeonggi_camp_info['Num'] = gyeonggi_camp_info['Num'].astype('int')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6793832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gyeonggi_camp_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec35df",
   "metadata": {},
   "source": [
    "# 캠핑장 리뷰 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa51325",
   "metadata": {},
   "outputs": [],
   "source": [
    "camping_num_list  = []\n",
    "camping_addr_list = []\n",
    "camping_name_list = []\n",
    "user_id_list      = []\n",
    "camping_type_list = []\n",
    "rating_list       = []\n",
    "avg_rating_list   = []\n",
    "date_list         = []\n",
    "review_list       = []\n",
    "count_list        = []\n",
    "error             = [] # 에러 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e91d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_crawl():\n",
    "    driver = webdriver.Chrome('../driver/chromedriver.exe')\n",
    "\n",
    "    for i in range(6,8):\n",
    "\n",
    "        review_url = 'https://pcmap.place.naver.com/accommodation/{}/review/visitor?'.format(gyeonggi_camp_info['Num'][i])\n",
    "    #     print(review_url)\n",
    "        try:\n",
    "            print('======================================================')\n",
    "            print(str(i+1)+'번째 캠핑장')\n",
    "\n",
    "            # 캠핑장 리뷰 개별 url 접속\n",
    "            driver.get(review_url)\n",
    "            time.sleep(2) \n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    # END 키를 눌러서 페이지 제일 하단으로 이동\n",
    "                    driver.find_element_by_tag_name('body').send_keys(Keys.END)\n",
    "                    time.sleep(3)\n",
    "                    # 더보기 버튼 클릭\n",
    "                    driver.find_element_by_xpath('//*[@id=\"app-root\"]/div/div/div[2]/div[5]/div[4]/div[4]/div[2]/a').click()\n",
    "                    time.sleep(3)\n",
    "                    # END 키를 눌러서 페이지 제일 하단으로 이동\n",
    "                    driver.find_element_by_tag_name('body').send_keys(Keys.END)\n",
    "                    time.sleep(1)\n",
    "\n",
    "                except NoSuchElementException:\n",
    "                    print('-더보기 버튼 모두 클릭 완료-')\n",
    "                    break\n",
    "\n",
    "            # 파싱\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "            time.sleep(1)\n",
    "\n",
    "            # 캠핑장 구분\n",
    "            camping_site_name = gyeonggi_camp_info['Name'][i]\n",
    "            print('사업장명 : '+ camping_site_name)\n",
    "\n",
    "            try:\n",
    "                all_review = soup.find_all('div', attrs = {'class':'_1Z_GL'})\n",
    "                review_num = len(all_review) # 특정 캠핑의 리뷰 총 개수\n",
    "                print('리뷰 총 개수 : '+ str(review_num))\n",
    "\n",
    "                print('----------------------------------------------')\n",
    "\n",
    "                for review in range(review_num):\n",
    "                    ## 캠핑장 고유 넘버 \n",
    "                    camping_num_list.append(gyeonggi_camp_info[\"Num\"][i])\n",
    "\n",
    "                    ## 캠핑장주소\n",
    "                    camping_addr_list.append(gyeonggi_camp_info[\"Address\"][i])                         \n",
    "\n",
    "                    ## 캠핑장 이름\n",
    "                    camping_name_list.append(camping_site_name)\n",
    "                    print(camping_site_name)\n",
    "\n",
    "                    ## user ID\n",
    "                    user = soup.find_all('div',{'class':'hbo4A'})\n",
    "                    print('{}번째 user:'.format(review+1),user[review].text)\n",
    "                    user_id_list.append(user[review].text)\n",
    "\n",
    "                    ## rating(사용자가 이 캠핑장에 준 별점)\n",
    "                    rating = all_review[review].find('span', attrs = {'class':'_2tObC'}).text\n",
    "                    print('rating = '+rating)\n",
    "                    rating_list.append(rating)\n",
    "\n",
    "                    ## 사용자의 평균 별점\n",
    "                    avg_rating = soup.find_all('div',{'class':'ql4ZC'})\n",
    "                    print('avg_rating ='+avg_rating[review].text)\n",
    "                    avg_rating_list.append(avg_rating[review].text)\n",
    "\n",
    "                    # 주의!!! 사진 리뷰 유무에 따라 날짜 파싱코드 다름\n",
    "                    # ('span', attrs = {'class':'_3WqoL'})\n",
    "                    # 사진 없는 경우 : 총 6개 중 4번째\n",
    "                    # 사진 있는 경우 : 총 5개 중 3번째\n",
    "\n",
    "                    ## date\n",
    "                    # 사진 리뷰 없음\n",
    "                    if len(all_review[review].find_all('span', attrs = {'class':'_3WqoL'})) == 5:\n",
    "                        date = all_review[review].find_all('span', attrs = {'class':'_3WqoL'})[2].text\n",
    "                    elif len(all_review[review].find_all('span', attrs = {'class':'_3WqoL'})) == 6:\n",
    "                        date = all_review[review].find_all('span', attrs = {'class':'_3WqoL'})[3].text\n",
    "                    else:\n",
    "                        date = \"\"\n",
    "                    print('date = '+date)\n",
    "                    date_list.append(date)\n",
    "\n",
    "                    ## count 방문횟수\n",
    "                    if len(all_review[review].find_all('span', attrs = {'class':'_3WqoL'})) == 5:\n",
    "                        count = all_review[review].find_all('span', attrs = {'class':'_3WqoL'})[3].text\n",
    "                    elif len(all_review[review].find_all('span', attrs = {'class':'_3WqoL'})) == 6:\n",
    "                        count = all_review[review].find_all('span', attrs = {'class':'_3WqoL'})[4].text\n",
    "                    else:\n",
    "                        count = \"\"\n",
    "                    print('방문횟수 = '+count)\n",
    "                    count_list.append(count)                \n",
    "\n",
    "                    ## review 내용\n",
    "                    try: \n",
    "                        review_content = all_review[review].find('span', attrs = {'class':'WoYOw'}).text\n",
    "                    except: # 리뷰가 없다면\n",
    "                        review_content = \"\"\n",
    "                    print('리뷰 내용 : '+review_content)\n",
    "                    review_list.append(review_content)                    \n",
    "\n",
    "                    print('\\n\\n')\n",
    "\n",
    "            except Exception as total_review_err:\n",
    "                none_review = \"네이버 리뷰 0개\"\n",
    "                print(none_review)   \n",
    "\n",
    "\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            error_list = '{}행 에러 : {}'.format(i,err)\n",
    "            error.append(error_list)\n",
    "            rating_list.append(' ')\n",
    "            avg_rating_list.append(' ')\n",
    "            review_list.append(' ')\n",
    "\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402c7530",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_crawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11deff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = {'Num':camping_num_list,'Address':camping_addr_list,'Date':date_list, 'Name':camping_name_list, 'User_ID':user_id_list, 'Rating':rating_list, \n",
    "               'Avg_rating':avg_rating_list, 'Review':review_list}\n",
    "review_df = pd.DataFrame(review_data)\n",
    "review_df\n",
    "\n",
    "review = []\n",
    "avg_ratings = []\n",
    "for i in review_df['Avg_rating'].tolist():\n",
    "    a = re.findall('\\d+[.]?\\d*', i)\n",
    "    try:\n",
    "        review.append(a[0])\n",
    "        avg_ratings.append(a[-1])    \n",
    "    except:\n",
    "        review.append('none')\n",
    "        avg_ratings.append('none')  \n",
    "\n",
    "review_df['Total_Review']=review\n",
    "review_df['User_Avg_Ratings']=avg_ratings\n",
    "\n",
    "review_final = review_df[['Num','Date','Name','Address','User_ID','Total_Review','User_Avg_Ratings','Rating','Review']]\n",
    "review_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497fc4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_final.to_csv('review_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
